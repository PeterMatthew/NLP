{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import itertools\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "corpus = api.load('text8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['which', 'leads', 'me', 'to', 'say', 'why', 'are', 'you', 'using', 'c', 'to', 'do', 'x', 'because', 'they', 'know', 'c', 'it', 's', 'fast', 'and', 'it', 'has', 'lots', 'of', 'libs', 'available', 'they', 'might', 'also', 'dislike', 'java', 'or', 'cl', 'not', 'every', 'engineering', 'decision', 'is', 'perfect', 'lots', 'of', 'factors', 'play', 'in', 'attempts', 'to', 'combine', 'the', 'best', 'of', 'c', 'speed', 'with', 'the', 'best', 'of', 'scripting', 'languages', 'easy', 'to', 'do', 'things', 'fast', 'without', 'having', 'to', 'pay', 'attention', 'to', 'what', 'you', 'are', 'doing', 'in', 'my', 'opinion', 'end', 'up', 'merely', 'joining', 'the', 'worst', 'of', 'both', 'worlds', 'rather', 'than', 'the', 'best', 'of', 'both', 'worlds', 'the', 'pay', 'attention', 'things', 'is', 'to', 'needless', 'complexity', 'memory', 'management', 'etc', 'they', 'only', 'reason', 'we', 'put', 'up', 'with', 'those', 'things', 'was', 'to', 'get', 'speed', 'if', 'we', 'can', 'get', 'adequate', 'speed', 'without', 'those', 'nobody', 'cares', 'about', 'them', 'besides', 'isn', 't', 'programming', 'about', 'being', 'specific', 'do', 'you', 'really', 'want', 'to', 'code', 'stuff', 'without', 'having', 'to', 'worry', 'about', 'the', 'details', 'no', 'programming', 'is', 'about', 'getting', 'results', 'nobody', 'cares', 'about', 'the', 'details', 'in', 'the', 'level', 'of', 'programming', 'language', 'minutuae', 'we', 'care', 'about', 'the', 'effort', 'put', 'in', 'and', 'quality', 'speed', 'of', 'results', 'coming', 'out', 'ratio']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/hacker_news_sample.csv')\n",
    "df = df.dropna(subset=['text'])\n",
    "# remove html symbols\n",
    "df['text'] = df['text'].apply(lambda row: re.sub('\\<[^>]*\\>', ' ', row))\n",
    "df['text'] = df['text'].apply(lambda row: re.sub('\\&[^;]*\\;', ' ', row))\n",
    "\n",
    "df['text'] = df['text'].apply(lambda row: re.sub('\\d', '', row).lower())\n",
    "df['text'] = df['text'].apply(lambda row: row.translate(str.maketrans('', '', string.punctuation)))\n",
    "df['tokenized'] = df['text'].apply(lambda row: nltk.word_tokenize(row))\n",
    "\n",
    "print(df['tokenized'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. O objetivo dessa questão é desenvolver um buscador de documentos.\\n\n",
    "a) escolha e aplique um modelo do tipo word2vec a seus textos, compatível com o idioma de seus textos (inglês ou português)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(df['tokenized'])\n",
    "model = Word2Vec(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) escolha 5 palavras de consulta que não estejam em nenhum dos textos. Para cada palavra de consulta, encontre as 3 palavras de seu conjunto de textos mais parecidas com cada uma das palavras de consulta e exiba os documentos onde estas palavras aparecem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507363\n",
      "word \"draconian\" not in dataset\n",
      "word \"jakarta\" not in dataset\n",
      "word \"anachronism\" not in dataset\n",
      "word \"appoint\" not in dataset\n",
      "bottleneck -> [('prediction', 0.35406077), ('gon', 0.34344906), ('struck', 0.34233242)]\n",
      "draconian -> [('matters', 0.62689024), ('accomplished', 0.6255134), ('opposition', 0.62537265)]\n",
      "jakarta -> [('engagement', 0.43495196), ('credible', 0.42365366), ('warrant', 0.4232228)]\n",
      "anachronism -> [('frustration', 0.30974063), ('casually', 0.30972105), ('overnight', 0.3063045)]\n",
      "appoint -> [('out', 0.2260439), ('use', 0.2211654), ('give', 0.21638574)]\n"
     ]
    }
   ],
   "source": [
    "words = ['bottleneck', 'draconian', 'jakarta', 'anachronism', 'appoint']\n",
    "print(len(list(itertools.chain(*df['tokenized'].tolist()))))\n",
    "for word in words:\n",
    "    if word not in list(itertools.chain(*df['tokenized'].tolist())):\n",
    "        print(f'word \"{word}\" not in dataset')\n",
    "\n",
    "for word in words:\n",
    "    similarities = []\n",
    "    for word2 in list(itertools.chain(*df['tokenized'].tolist())):\n",
    "        if word2 in w2v.wv:\n",
    "            vec1 = w2v.wv[word2]\n",
    "            vec2 = model.wv[word]\n",
    "            similarities.append((word2, np.sum(vec1*vec2)/(np.linalg.norm(vec1)*np.linalg.norm(vec2))))\n",
    "    print(word, '->', sorted(list(dict(similarities).items()), key=lambda x: x[1], reverse=True)[:3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Seja d um documento da base e w uma palavra de consulta. Implemente o seguinte algoritmo para buscar documentos:\n",
    "1. Encontre d10(w): a lista com as 10 palavras mais parecidas com w em um certo documento d.\n",
    "2. Para cada documento d, calcule a distância média DM10(w) entre w e as palavras de d10(w).\n",
    "3. Recupere os 3 documentos da base cuja DM10(w)  ́e menor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3503f95e0e8f4afdf6702396a7a2a29cae9f67572acfe092405dcaa2579b817"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
